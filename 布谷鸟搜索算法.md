
---

# **自我总结**：

---

- **实际要做的事情就是**：假设我们优化的是 $n$-维问题，即有$n$个待优化参数，把这$n$个待优化参数视为一个向量（和深度学习中是一样的，只不过深度学习中用通常用$\boldsymbol{\theta}$或$\vec{\boldsymbol{\theta}}$表示）。先随机初始化$N$个待优化参数向量，称为候选解，**一个候选解代表一个蛋，即[[#^bd822a|候选解矩阵]]中的每一行的向量代表蛋，而矩阵每一行的本身就代表一个巢，行的序号就代表巢的编号，即矩阵每一行都是一个巢，所以也能说有多少个候选解就代表有多少个巢（即种群规模，为超参数）**。所以，随机初始化$N$个待优化参数向量也即初始化[[#^bd822a|候选解矩阵]]，然后通过Lévy飞行这种长尾分布的更新策略（即$x^{(t+1)} = x^{(t)} + \alpha \cdot \text{Lévy}(\lambda)$）（也即步长$\text{Lévy}(\lambda)$为随机值，服从长尾分布）来产生新的蛋（即新的参数向量），然后随机挑选一个巢（即候选解矩阵中的某一行）把新蛋与该巢原有的蛋进行对比（即对比：使用旧参数向量进行推理时损失函数的值，和使用新参数向量进行推理时的损失函数的值）（另：在布谷鸟搜索中一般把损失函数称为适应度函数），把适应度低的蛋抛弃。 ^e08f00
- **候选解的个数代表有多少个巢（即种群规模），[[#^bd822a|候选解矩阵]]中的每一行中的向量的值代表蛋，行的序号代表巢（即有多少行就代表有多少个巢）。**
- 需要注意，有一个和仿生不太对应的地方就是，算法中新蛋向量的生成其实是基于某个巢中的旧蛋向量。这是为了**有效利用当前解的“局部信息”**，而非完全盲目搜索，保留局部搜索的连续性，又融合了大步探索跳出局部最优
- 所以布谷鸟搜索算法中跳出局部最优是有两个机制，一个是levy飞行属于长尾分布，一个是pa参数随机毁巢

---
- **候选解和候选解矩阵**：
假设我们优化的是 $n$-维问题，即有$n$个待优化参数，把这$n$个待优化参数视为一个向量（和深度学习中是一样的，只不过深度学习中用通常用$\boldsymbol{\theta}$或$\vec{\boldsymbol{\theta}}$表示），然后初始化$N$个，即 $N$ 个巢（巢的个数为超参数），矩阵中的每行就代表一个待优化向量，那么候选解可以用一个矩阵表示： ^bd822a

$$
\text{Nests} =
\begin{bmatrix}
x_1^{(1)} & x_2^{(1)} & \cdots & x_n^{(1)} \\
x_1^{(2)} & x_2^{(2)} & \cdots & x_n^{(2)} \\
\vdots & \vdots & \ddots & \vdots \\
x_1^{(N)} & x_2^{(N)} & \cdots & x_n^{(N)}
\end{bmatrix}
$$

---
---

# 🐦 布谷鸟搜索算法（Cuckoo Search Algorithm）简明总结（此为基于上面自我总结内容的AI总结）



---
## 一、问题背景

我们希望优化一个 **$n$ 维参数问题**，即有 $n$ 个待优化参数。可以将这些参数表示为一个向量，类似深度学习中常用的符号 $\boldsymbol{\theta}$或手写时的$\vec{\boldsymbol{\theta}}$。
## 二、基本概念

### 1. 候选解与候选解矩阵

- 将待优化的参数看作一个 $n$ 维向量。
- 初始化 $N$ 个这样的向量，构成一个 **$N \times n$ 的矩阵**，记作“候选解矩阵”。
- 这个矩阵的每一行中的向量是一个候选解，也称为“一个巢（nest）”中的“一个蛋（egg）”。而矩阵的每一行本身即为一个巢。

### 候选解矩阵形式如下：

$$
\text{Nests} =
\begin{bmatrix}
x_1^{(1)} & x_2^{(1)} & \cdots & x_n^{(1)} \\\\
x_1^{(2)} & x_2^{(2)} & \cdots & x_n^{(2)} \\\\
\vdots & \vdots & \ddots & \vdots \\\\
x_1^{(N)} & x_2^{(N)} & \cdots & x_n^{(N)}
\end{bmatrix}
$$

- 其中第 $i$ 行是第 $i$ 个巢，包含一个 $n$ 维参数向量（即一个蛋）（也即一个候选解）。
- 所以，“**巢的数量 = 候选解数量 = 矩阵行数 = 种群规模**”，这是一个超参数。
## 三、算法核心机制

### 1. Lévy 飞行生成新解（新蛋）

- 使用 Lévy 分布（重尾分布）进行更新：

$$
\boldsymbol{x}^{(t+1)} = \boldsymbol{x}^{(t)} + \alpha \cdot \text{Lévy}(\lambda)
$$

- 其中 $\alpha$ 是步长控制因子，$\text{Lévy}(\lambda)$ 是从重尾分布**$\text{Lévy}$分布**中采样的随机向量。
- 新向量是在当前解附近生成的，体现了**局部搜索连续性**与**跳出局部最优的能力**。
- **需要注意，有一个和仿生不太对应的地方就是，算法中新蛋向量的生成其实是基于某个巢中的旧蛋向量。**这是为了有效利用当前解的“局部信息”，而非完全盲目搜索，保留局部搜索的连续性，又融合了大步探索跳出局部最优
### 2. 适应度比较与替换

- 随机挑选一个巢，将新生成的蛋与旧蛋进行适应度函数（即损失函数）值比较：
  - 若新蛋更优，则替换旧蛋；
  - 否则保持原状。

### 3. 概率性毁巢机制（破坏局部最优）

- 使用一个概率 $p_a$ 随机替换部分巢，以防陷入局部最优。
- 这个机制模拟“宿主鸟发现了外来蛋并弃巢”的生物行为。
## 四、要点归纳

| 概念         | 含义                                     |
| ---------- | -------------------------------------- |
| 候选解        | 一个 $n$ 维参数向量（一个“蛋”）                    |
| 巢（Nest）    | 候选解矩阵的一行（指此行本身，而不是该行中“存放”着的向量），每个巢有一个蛋 |
| 种群规模 $N$   | 候选解矩阵的行数，表示有多少个巢                       |
| Lévy 飞行    | 一种重尾分布的更新策略，生成新解                       |
| 适应度函数      | 用来评估参数向量好坏的目标函数（即深度学习中的损失函数）           |
| 毁巢概率 $p_a$ | 随机丢弃一部分巢以增加全局搜索能力                      |
## 五、直观理解

- 整个算法模拟布谷鸟在其他鸟巢中产卵的行为。
- 每个“巢”就是对应矩阵中的一行，“蛋”是该行中“存放”着的具体的参数向量。
- 通过 Lévy 飞行生成新蛋（新解），不断替换旧蛋（差解），逐步优化参数。
- 结合毁巢机制，保证算法既能**局部细致搜索**，也能**全局跳跃搜索**，避免陷入局部最优。
