# Qwen
```bash
# ONNXruntime官方脚本启动qwen14B的ONNX模型
python model-chat.py   -m ~/deepseek-qwen14B-int4/deepseek-r1-distill-qwen-14B/gpu/gpu-int4-rtn-block-32/   -e cuda   --chat_template "<|begin▁of▁sentence|><|User|>{input}<|Assistant|>"   --max_length 2048
```
# YOLOv5
[官方仓库releases](https://github.com/ultralytics/yolov5/releases)

```python
# yolo_batchPic_ONNX_runtime.py
import os  
import cv2  
import numpy as np  
import onnxruntime as ort  
from glob import glob  
from tqdm import tqdm  
  
# 参数区  
model_path = 'yolov5m.onnx'          # 你的ONNX模型路径  
image_dir = r'C:\Users\zcxxj\Desktop\my_proj\data\archive\test'  # 测试图片目录  
output_dir = 'outputs/'              # 推理结果保存目录  
input_size = 640                     # 模型输入尺寸  
conf_thres = 0.25                    # 置信度阈值  
iou_thres = 0.45                     # NMS阈值  
  
# 类别名（COCO）  
COCO_CLASSES = [  
    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',  
    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',  
    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',  
    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',  
    'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',  
    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',  
    'potted plant', 'bed', 'dining table', 'toilet', 'TV', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',  
    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',  
    'hair drier', 'toothbrush'  
]  
  
# 中文名暂不可用cv2打印  
# COCO_CLASSES = [  
#     '人', '自行车', '汽车', '摩托车', '飞机', '公交车', '火车', '卡车', '船', '红绿灯',  
#     '消防栓', '停止标志', '停车计时器', '长椅', '鸟', '猫', '狗', '马', '羊', '牛',  
#     '大象', '熊', '斑马', '长颈鹿', '背包', '雨伞', '手提包', '领带', '手提箱', '飞盘',  
#     '滑雪板', '滑雪橇', '运动球', '风筝', '棒球棒', '棒球手套', '滑板', '冲浪板',  
#     '网球拍', '瓶子', '酒杯', '杯子', '叉子', '刀', '勺子', '碗', '香蕉', '苹果',  
#     '三明治', '橙子', '西兰花', '胡萝卜', '热狗', '披萨', '甜甜圈', '蛋糕', '椅子', '沙发',  
#     '盆栽植物', '床', '餐桌', '马桶', '电视', '笔记本电脑', '鼠标', '遥控器', '键盘', '手机',  
#     '微波炉', '烤箱', '烤面包机', '水槽', '冰箱', '书', '钟', '花瓶', '剪刀', '泰迪熊',  
#     '吹风机', '牙刷'  
# ]  
  
  
# Letterbox处理  
def letterbox(im, new_shape=640, color=(114, 114, 114)):  
    shape = im.shape[:2]  
    if isinstance(new_shape, int):  
        new_shape = (new_shape, new_shape)  
    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])  
    new_unpad = (int(round(shape[1] * r)), int(round(shape[0] * r)))  
    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  
    dw /= 2  
    dh /= 2  
    im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)  
    top, bottom = int(round(dh-0.1)), int(round(dh+0.1))  
    left, right = int(round(dw-0.1)), int(round(dw+0.1))  
    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  
    return im, r, (dw, dh)  
  
# 预处理  
def preprocess(img_path, input_size):  
    img = cv2.imread(img_path)  
    if img is None:  
        raise ValueError(f"无法读取图像 {img_path}")  
    img0 = img.copy()  
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  
    img, r, (dw, dh) = letterbox(img, new_shape=input_size)  
    img_chw = img.transpose(2, 0, 1)  
    img_normalized = (img_chw / 255.0).astype(np.float16)  
    input_tensor = np.expand_dims(img_normalized, axis=0)  
    return img0, input_tensor, r, dw, dh  
  
# 后处理  
def postprocess(predictions, img_shape, r, dw, dh, conf_thres=0.25, iou_thres=0.45):  
    preds = predictions[0]  
    boxes, confidences, class_ids = [], [], []  
  
    for pred in preds:  
        scores = pred[5:]  
        class_id = np.argmax(scores)  
        confidence = scores[class_id] * pred[4]  
        if not np.isfinite(confidence) or confidence < conf_thres:  
            continue  
        if not np.all(np.isfinite(pred[0:4])):  
            continue  
        cx, cy, w, h = pred[0:4]  
        x1 = (cx - w/2) - dw  
        y1 = (cy - h/2) - dh  
        x2 = (cx + w/2) - dw  
        y2 = (cy + h/2) - dh  
        x1 /= r  
        y1 /= r  
        x2 /= r  
        y2 /= r  
        box = [int(x1), int(y1), int(x2), int(y2)]  
        boxes.append(box)  
        confidences.append(float(confidence))  
        class_ids.append(class_id)  
  
    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_thres, iou_thres)  
    results = []  
    if len(indices) > 0:  
        for i in indices.flatten():  
            results.append((boxes[i], confidences[i], class_ids[i]))  
    return results  
  
# 绘制检测框  
def draw_boxes(img, results):  
    for box, score, class_id in results:  
        x1, y1, x2, y2 = box  
        label = f"{COCO_CLASSES[class_id]} {score:.2f}" if class_id < len(COCO_CLASSES) else f"id{class_id} {score:.2f}"  
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)  
        cv2.putText(img, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1)  
    return img  
  
# 创建Session  
def create_session(model_path):  
    providers = ['DmlExecutionProvider', 'CPUExecutionProvider']  
    sess = ort.InferenceSession(model_path, providers=providers)  
    print("当前使用的执行后端:", sess.get_providers())  
    return sess  
  
# === 主程序 ===if __name__ == '__main__':  
    os.makedirs(output_dir, exist_ok=True)  
  
    sess = create_session(model_path)  
    image_paths = glob(os.path.join(image_dir, '*.jpg'))  
    print(f"找到 {len(image_paths)} 张图片，开始推理...")  
  
    for img_path in tqdm(image_paths, desc="推理中"):  
        try:  
            img0, input_tensor, r, dw, dh = preprocess(img_path, input_size)  
            outputs = sess.run(None, {sess.get_inputs()[0].name: input_tensor})  
            outputs = outputs[0]  # ➡️ 取第一项，跟单张推理保持一致  
            results = postprocess(outputs, img0.shape[:2], r, dw, dh, conf_thres, iou_thres)  
            img_drawn = draw_boxes(img0, results)  
  
            save_path = os.path.join(output_dir, os.path.basename(img_path))  
            cv2.imwrite(save_path, img_drawn)  
        except Exception as e:  
            print(f"处理 {img_path} 出错: {e}")  
  
    print("批量推理完成，结果保存在:", output_dir)

```

```python
# YOLO_ONNX_BY_openvino_runtime.py
# openvino是由intel提供的ONNX运行时，可用NPU
import os  
import cv2  
import numpy as np  
from glob import glob  
from tqdm import tqdm  
from openvino.runtime import Core  
import time  
  
# ==================== 参数区 ====================model_path = 'yolov5m.onnx'  # 你的 ONNX 模型路径  
image_dir = r'C:\Users\zcxxj\Desktop\my_proj\data\archive\test'  # 测试图片目录  
output_dir = 'outputs_openvino/'  # 输出文件夹  
input_size = 640  # 输入尺寸（YOLOv5标准）  
conf_thres = 0.25  # 置信度阈值  
iou_thres = 0.45  # NMS阈值  
  
# 设备选择: "AUTO", "CPU", "GPU", "NPU"  
device = "AUTO"  
  
COCO_CLASSES = [  
    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',  
    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',  
    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',  
    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',  
    'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',  
    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',  
    'potted plant', 'bed', 'dining table', 'toilet', 'TV', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',  
    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',  
    'hair drier', 'toothbrush'  
]  
  
# ==================== 工具函数 ====================def letterbox(im, new_shape=640, color=(114, 114, 114)):  
    shape = im.shape[:2]  
    if isinstance(new_shape, int):  
        new_shape = (new_shape, new_shape)  
    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])  
    new_unpad = (int(round(shape[1] * r)), int(round(shape[0] * r)))  
    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  
    dw /= 2  
    dh /= 2  
    im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)  
    top, bottom = int(round(dh-0.1)), int(round(dh+0.1))  
    left, right = int(round(dw-0.1)), int(round(dw+0.1))  
    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  
    return im, r, (dw, dh)  
  
def preprocess(img_path, input_size):  
    img = cv2.imread(img_path)  
    if img is None:  
        raise ValueError(f"无法加载图像 {img_path}")  
    img0 = img.copy()  
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  
    img, r, (dw, dh) = letterbox(img, new_shape=input_size)  
    img = img.transpose(2, 0, 1)  
    img = np.expand_dims(img, axis=0)  
    img = img.astype(np.float32) / 255.0  
    return img0, img, r, dw, dh  
  
def postprocess(prediction, img_shape, r, dw, dh, conf_thres=0.25, iou_thres=0.45):  
    preds = prediction.squeeze(0)  
    boxes, confidences, class_ids = [], [], []  
    for pred in preds:  
        scores = pred[5:]  
        class_id = np.argmax(scores)  
        confidence = scores[class_id] * pred[4]  
        if not np.isfinite(confidence) or confidence < conf_thres:  
            continue  
        if not np.all(np.isfinite(pred[0:4])):  
            continue  
        cx, cy, w, h = pred[0:4]  
        x1 = (cx - w/2) - dw  
        y1 = (cy - h/2) - dh  
        x2 = (cx + w/2) - dw  
        y2 = (cy + h/2) - dh  
        x1 /= r  
        y1 /= r  
        x2 /= r  
        y2 /= r  
        boxes.append([int(x1), int(y1), int(x2), int(y2)])  
        confidences.append(float(confidence))  
        class_ids.append(class_id)  
    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_thres, iou_thres)  
    results = []  
    if len(indices) > 0:  
        for i in indices.flatten():  
            results.append((boxes[i], confidences[i], class_ids[i]))  
    return results  
  
def draw_boxes(img, results):  
    for box, score, class_id in results:  
        x1, y1, x2, y2 = box  
        label = f"{COCO_CLASSES[class_id]} {score:.2f}" if class_id < len(COCO_CLASSES) else f"id{class_id} {score:.2f}"  
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)  
        cv2.putText(img, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 0, 0), 2)  
    return img  
  
# ==================== 主程序 ====================if __name__ == '__main__':  
    os.makedirs(output_dir, exist_ok=True)  
  
    core = Core()  
    model = core.read_model(model_path)  
    compiled_model = core.compile_model(model, device)  
  
    device_name = core.get_property(device, "FULL_DEVICE_NAME")  
    print(f"实际推理设备: {device_name}")  
  
    input_tensor = compiled_model.inputs[0]  
    output_tensor = compiled_model.outputs[0]  
  
    image_paths = glob(os.path.join(image_dir, '*.jpg'))  
    print(f"找到 {len(image_paths)} 张图片，开始推理...")  
  
    total_time = 0  
    for img_path in tqdm(image_paths, desc="推理中"):  
        try:  
            img0, input_tensor_data, r, dw, dh = preprocess(img_path, input_size)  
            start_time = time.time()  
            preds = compiled_model([input_tensor_data])[output_tensor]  
            elapsed = time.time() - start_time  
            total_time += elapsed  
  
            results = postprocess(preds, img0.shape[:2], r, dw, dh, conf_thres, iou_thres)  
            img_drawn = draw_boxes(img0, results)  
  
            save_path = os.path.join(output_dir, os.path.basename(img_path))  
            cv2.imwrite(save_path, img_drawn)  
        except Exception as e:  
            print(f"处理 {img_path} 出错: {e}")  
  
    print(f"\n全部完成，平均每张推理时间: {total_time/len(image_paths)*1000:.2f} ms")  
    print(f"结果保存在: {output_dir}")
```

```python
# yolo_ONNX_runtime_singlePic.py
import onnxruntime as ort  
import numpy as np  
import cv2  
  
# 参数区  
model_path = 'yolov5m.onnx'  # 你的ONNX模型路径  
image_path = r'C:\Users\zcxxj\Desktop\my_proj\my_code\9754d210b329b289d67f7afe979884f.jpg'  # 你的测试图片路径  
input_size = 640             # 输入尺寸  
conf_thres = 0.25            # 置信度阈值  
iou_thres = 0.45             # NMS阈值  
  
COCO_CLASSES = [  
    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',  
    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',  
    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',  
    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',  
    'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',  
    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',  
    'potted plant', 'bed', 'dining table', 'toilet', 'TV', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',  
    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',  
    'hair drier', 'toothbrush'  
]  
# COCO_CLASSES = [  
#     '人', '自行车', '汽车', '摩托车', '飞机', '公交车', '火车', '卡车', '船', '红绿灯',  
#     '消防栓', '停止标志', '停车计时器', '长椅', '鸟', '猫', '狗', '马', '羊', '牛',  
#     '大象', '熊', '斑马', '长颈鹿', '背包', '雨伞', '手提包', '领带', '手提箱', '飞盘',  
#     '滑雪板', '滑雪橇', '运动球', '风筝', '棒球棒', '棒球手套', '滑板', '冲浪板',  
#     '网球拍', '瓶子', '酒杯', '杯子', '叉子', '刀', '勺子', '碗', '香蕉', '苹果',  
#     '三明治', '橙子', '西兰花', '胡萝卜', '热狗', '披萨', '甜甜圈', '蛋糕', '椅子', '沙发',  
#     '盆栽植物', '床', '餐桌', '马桶', '电视', '笔记本电脑', '鼠标', '遥控器', '键盘', '手机',  
#     '微波炉', '烤箱', '烤面包机', '水槽', '冰箱', '书', '钟', '花瓶', '剪刀', '泰迪熊',  
#     '吹风机', '牙刷'  
# ]  
  
  
# Step 1: Letterbox（保持比例缩放）  
def letterbox(im, new_shape=640, color=(114, 114, 114)):  
    shape = im.shape[:2]  # h,w  
    if isinstance(new_shape, int):  
        new_shape = (new_shape, new_shape)  
  
    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])  
    new_unpad = (int(round(shape[1] * r)), int(round(shape[0] * r)))  
  
    dw = new_shape[1] - new_unpad[0]  # width padding  
    dh = new_shape[0] - new_unpad[1]  # height padding  
    dw /= 2  
    dh /= 2  
  
    im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)  
    top, bottom = int(round(dh-0.1)), int(round(dh+0.1))  
    left, right = int(round(dw-0.1)), int(round(dw+0.1))  
    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  
  
    return im, r, (dw, dh)  
  
# Step 2: 预处理图片  
def preprocess(image_path, input_size):  
    img = cv2.imread(image_path)  
    if img is None:  
        raise ValueError(f"无法加载图像 {image_path}")  
  
    img0 = img.copy()  # 保留原图  
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  
    img, r, (dw, dh) = letterbox(img, new_shape=input_size)  
  
    img_chw = img.transpose(2, 0, 1)  
    img_normalized = (img_chw / 255.0).astype(np.float16)  # 注意：float16  
    input_tensor = np.expand_dims(img_normalized, axis=0)  
  
    return img0, input_tensor, r, dw, dh  
  
# Step 3: 创建 Sessiondef create_session(model_path):  
    providers = ['DmlExecutionProvider', 'CPUExecutionProvider']  
    sess = ort.InferenceSession(model_path, providers=providers)  
    print("当前使用的执行后端:", sess.get_providers())  
    return sess  
  
# Step 4: 推理  
def infer(sess, input_tensor):  
    input_name = sess.get_inputs()[0].name  
    outputs = sess.run(None, {input_name: input_tensor})  
    return outputs[0]  
  
# Step 5: 后处理  
def postprocess(predictions, img_shape, r, dw, dh, conf_thres=0.25, iou_thres=0.45):  
    preds = predictions[0]  
  
    boxes = []  
    confidences = []  
    class_ids = []  
  
    for pred in preds:  
        scores = pred[5:]  
        class_id = np.argmax(scores)  
        confidence = scores[class_id] * pred[4]  
  
        if not np.isfinite(confidence) or confidence < conf_thres:  
            continue  
        if not np.all(np.isfinite(pred[0:4])):  
            continue  
  
        cx, cy, w, h = pred[0:4]  
        # 还原回到letterbox前的原图尺寸  
        x1 = (cx - w/2) - dw  
        y1 = (cy - h/2) - dh  
        x2 = (cx + w/2) - dw  
        y2 = (cy + h/2) - dh  
  
        x1 /= r  
        y1 /= r  
        x2 /= r  
        y2 /= r  
  
        box = [int(x1), int(y1), int(x2), int(y2)]  
  
        boxes.append(box)  
        confidences.append(float(confidence))  
        class_ids.append(class_id)  
  
    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_thres, iou_thres)  
  
    results = []  
    if len(indices) > 0:  
        for i in indices.flatten():  
            results.append((boxes[i], confidences[i], class_ids[i]))  
  
    return results  
  
# Step 6: 画检测框  
def draw_boxes(img, results):  
    for box, score, class_id in results:  
        x1, y1, x2, y2 = box  
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)  
        label = f"{COCO_CLASSES[class_id]} {score:.2f}"  
        cv2.putText(img, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (255, 0, 0), 2)  
    return img  
  
def resize_to_screen(img, max_size=1280):  
    """自动缩放图像以适应屏幕显示"""  
    h, w = img.shape[:2]  
    scale = min(max_size / h, max_size / w, 1.0)  # 不放大，只缩小  
    if scale < 1.0:  
        img = cv2.resize(img, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_AREA)  
    return img  
  
# === 主程序 ===if __name__ == '__main__':  
    img0, input_tensor, r, dw, dh = preprocess(image_path, input_size)  
    sess = create_session(model_path)  
    outputs = infer(sess, input_tensor)  
    results = postprocess(outputs, img0.shape[:2], r, dw, dh, conf_thres, iou_thres)  
  
    print(f"检测到 {len(results)} 个目标")  
    img_drawn = draw_boxes(img0, results)  
  
    # 显示结果  
    cv2.namedWindow('YOLO Detection', cv2.WINDOW_NORMAL)  # ➡️ 允许手动缩放窗口  
    img_show = resize_to_screen(img_drawn, max_size=1280)  # ➡️ 初始限制最大尺寸，不然太大  
    cv2.imshow('YOLO Detection', img_show)  
    cv2.waitKey(0)  # ➡️ 等待按键，不然窗口闪退  
    cv2.destroyAllWindows()
```
